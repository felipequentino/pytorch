{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9261033,"sourceType":"datasetVersion","datasetId":5603671}],"dockerImageVersionId":30761,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"O `DataLoader` é uma classe fundamental em PyTorch que facilita o carregamento e a manipulação de datasets. Ele oferece várias vantagens em relação ao uso direto dos dados do CSV:\n\n### 1. **Mini-batches**:\n   - **Vantagem**: Em vez de carregar todo o dataset de uma vez, o `DataLoader` divide o dataset em pequenos lotes (mini-batches) de tamanho especificado (`batch_size`).\n   - **Benefício**: Isso permite treinar o modelo de forma mais eficiente, especialmente em datasets grandes, pois você pode atualizar os pesos do modelo várias vezes em uma única época, sem precisar carregar todo o dataset na memória de uma só vez.\n\n### 2. **Shuffling (Embaralhamento)**:\n   - **Vantagem**: O `DataLoader` pode embaralhar os dados a cada época (`shuffle=True`).\n   - **Benefício**: Embaralhar os dados ajuda a evitar que o modelo aprenda a ordem dos dados e melhora a generalização, resultando em um melhor desempenho do modelo.\n\n### 3. **Multi-processamento**:\n   - **Vantagem**: Usando o parâmetro `num_workers`, o `DataLoader` pode carregar os dados em paralelo usando múltiplos processos.\n   - **Benefício**: Isso acelera o processo de leitura dos dados, especialmente em datasets grandes ou quando a leitura dos dados é lenta (por exemplo, ao carregar imagens de um disco).\n\n### 4. **Facilidade de Uso com GPUs**:\n   - **Vantagem**: O `DataLoader` integra-se bem com o treinamento em GPUs. Ele pode transferir automaticamente os mini-batches para a GPU, se necessário.\n   - **Benefício**: Simplifica o código e melhora a eficiência ao usar GPUs, já que os dados são processados em lotes e carregados na GPU em paralelo ao treinamento do modelo.\n\n### 5. **Abstração e Flexibilidade**:\n   - **Vantagem**: O `DataLoader` abstrai os detalhes da leitura de dados e os encapsula em uma interface simples e reutilizável. Ele suporta datasets personalizados e operações complexas, como amostragem ponderada ou criação de batches de tamanhos variados.\n   - **Benefício**: Permite que você se concentre na lógica de treinamento e não nos detalhes do gerenciamento de dados, tornando o código mais limpo e modular.\n\n### Exemplo Prático:\nSuponha que você tenha um dataset de 1 milhão de amostras. Carregar tudo isso na memória de uma vez pode ser inviável. Com o `DataLoader`, você pode carregar, por exemplo, 64 amostras por vez, processá-las, e depois carregar as próximas 64, até que todas sejam usadas em uma época. \n\nSe você usasse os dados diretamente do CSV sem o `DataLoader`, você teria que implementar manualmente todas essas funcionalidades (mini-batches, shuffling, multi-processamento), o que adicionaria complexidade e diminuiria a eficiência do seu código.\n\nEm resumo, o `DataLoader` oferece uma maneira eficiente, flexível e simples de trabalhar com datasets em PyTorch, especialmente em contextos de treinamento de modelos de machine learning.","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\nimport pandas as pd\nimport numpy as np\nimport torchvision\nimport torch\nimport math","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-27T18:44:52.449156Z","iopub.execute_input":"2024-08-27T18:44:52.449798Z","iopub.status.idle":"2024-08-27T18:44:54.204191Z","shell.execute_reply.started":"2024-08-27T18:44:52.449751Z","shell.execute_reply":"2024-08-27T18:44:54.203206Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class WineDataset(Dataset):\n    def __init__(self):\n        # data loading\n        xy = pd.read_csv('/kaggle/input/wine-csv/wine.csv')\n        self.x = torch.tensor(xy.iloc[:, 1:].values, dtype=torch.float32)\n        self.y = torch.tensor(xy.iloc[:, 0].values, dtype=torch.long)\n        self.n_samples = xy.shape[0]\n\n    def __getitem__(self, index):\n        return self.x[index], self.y[index]\n\n    def __len__(self):\n        return self.n_samples\n","metadata":{"execution":{"iopub.status.busy":"2024-08-27T18:59:49.106061Z","iopub.execute_input":"2024-08-27T18:59:49.106503Z","iopub.status.idle":"2024-08-27T18:59:49.114765Z","shell.execute_reply.started":"2024-08-27T18:59:49.106464Z","shell.execute_reply":"2024-08-27T18:59:49.113557Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"dataset = WineDataset()\ndataloader = DataLoader(dataset=dataset, batch_size=4, shuffle=True, num_workers=2)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-27T19:04:13.160405Z","iopub.execute_input":"2024-08-27T19:04:13.161449Z","iopub.status.idle":"2024-08-27T19:04:13.175107Z","shell.execute_reply.started":"2024-08-27T19:04:13.161400Z","shell.execute_reply":"2024-08-27T19:04:13.174011Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# training loop\nnum_epochs = 2\ntotal_samples = len(dataset)\nn_iterations = math.ceil(total_samples/4)\n\nfor epoch in range(num_epochs):\n    for i, (inputs, labels) in enumerate(dataloader):\n        # forward backward, update\n        if (i+1) % 5 == 0:\n            print(f'epoch {epoch+1}/{num_epochs}, step {i+1}/{n_iterations}, inputs {inputs.shape}')","metadata":{"execution":{"iopub.status.busy":"2024-08-27T19:07:02.145323Z","iopub.execute_input":"2024-08-27T19:07:02.145839Z","iopub.status.idle":"2024-08-27T19:07:02.556225Z","shell.execute_reply.started":"2024-08-27T19:07:02.145798Z","shell.execute_reply":"2024-08-27T19:07:02.554711Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"epoch 1/2, step 5/45, inputs torch.Size([4, 13])\nepoch 1/2, step 10/45, inputs torch.Size([4, 13])\nepoch 1/2, step 15/45, inputs torch.Size([4, 13])\nepoch 1/2, step 20/45, inputs torch.Size([4, 13])\nepoch 1/2, step 25/45, inputs torch.Size([4, 13])\nepoch 1/2, step 30/45, inputs torch.Size([4, 13])\nepoch 1/2, step 35/45, inputs torch.Size([4, 13])\nepoch 1/2, step 40/45, inputs torch.Size([4, 13])\nepoch 1/2, step 45/45, inputs torch.Size([2, 13])\nepoch 2/2, step 5/45, inputs torch.Size([4, 13])\nepoch 2/2, step 10/45, inputs torch.Size([4, 13])\nepoch 2/2, step 15/45, inputs torch.Size([4, 13])\nepoch 2/2, step 20/45, inputs torch.Size([4, 13])\nepoch 2/2, step 25/45, inputs torch.Size([4, 13])\nepoch 2/2, step 30/45, inputs torch.Size([4, 13])\nepoch 2/2, step 35/45, inputs torch.Size([4, 13])\nepoch 2/2, step 40/45, inputs torch.Size([4, 13])\nepoch 2/2, step 45/45, inputs torch.Size([2, 13])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Esse código implementa uma pipeline básica para treinamento de um modelo em PyTorch usando o dataset de vinho. Aqui está uma explicação detalhada de cada parte:\n\n1. **Definição da Classe `WineDataset`**:\n    - A classe `WineDataset` herda de `torch.utils.data.Dataset` e serve para carregar e preparar os dados para treinamento.\n    - **`__init__()`**: Carrega os dados de um arquivo CSV, converte as colunas de features (`x`) e rótulos (`y`) em tensores PyTorch, e armazena o número total de amostras.\n    - **`__getitem__()`**: Retorna um par (features, rótulo) para um índice específico. Isso permite que o DataLoader acesse os dados de maneira indexada.\n    - **`__len__()`**: Retorna o número total de amostras no dataset.\n\n2. **Inicialização do `DataLoader`**:\n    - O `DataLoader` é criado a partir do `WineDataset` e é configurado para fornecer batches de dados de tamanho 4, com os dados sendo embaralhados (`shuffle=True`) a cada época, e usa 2 workers para carregar os dados em paralelo (`num_workers=2`).\n\n3. **Loop de Treinamento**:\n    - **Variáveis de configuração**:\n        - `num_epochs = 2`: Define que o treinamento ocorrerá por 2 épocas.\n        - `total_samples`: O número total de amostras no dataset.\n        - `n_iterations`: Calcula o número de iterações por época, baseado no tamanho do batch (`batch_size=4`).\n    - **Loop principal**:\n        - O loop externo itera sobre as épocas, enquanto o loop interno (`enumerate(dataloader)`) itera sobre os batches de dados.\n        - Em cada iteração, os dados de entrada (`inputs`) e os rótulos (`labels`) são passados para o modelo (embora o modelo não esteja explícito neste código).\n        - A cada 5 iterações, uma mensagem de progresso é exibida, mostrando a época atual, o passo atual, o total de iterações, e a forma dos dados de entrada (`inputs.shape`).\n\n**Propósito**:\n- O código prepara um dataset de vinhos para ser usado em um processo de treinamento em PyTorch.\n- Ele ilustra como carregar dados, iterar sobre eles em batches, e acompanhar o progresso do treinamento.\n- Embora o loop de treinamento inclua apenas a lógica de iteração e impressão, em um cenário completo, você incluiria o passo de **forward** (passagem dos dados pelo modelo), **backward** (cálculo dos gradientes), e **update** (atualização dos pesos do modelo).\n\nEste código é, portanto, uma base para a implementação de um processo de treinamento supervisionado em PyTorch.","metadata":{}}]}